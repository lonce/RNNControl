{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transform\n",
    "\n",
    "import dataloader \n",
    "from transforms import mulawnEncode,mulaw,array2tensor,dic2tensor\n",
    "from paramManager import paramManager\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utility functions\n",
    "#*************************************\n",
    "def time_taken(elapsed):\n",
    "    \"\"\"To format time taken in hh:mm:ss. Use with time.monotic()\"\"\"\n",
    "    m, s = divmod(elapsed, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return \"%d:%02d:%02d\" % (h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read/write directory parameters\n",
    "#*************************************\n",
    "datadir = 'dataset'\n",
    "paramdir = 'dataparam'\n",
    "\n",
    "# Training parameters\n",
    "#*************************************\n",
    "sr = 16000\n",
    "seqLen = 256\n",
    "stride = 10\n",
    "batch_size = 25\n",
    "num_epochs = 1\n",
    "lr = 0.005\n",
    "log_interval = 20\n",
    "max_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['meta', 'rmse', 'instID', 'midiPitch'])\n"
     ]
    }
   ],
   "source": [
    "# Let's check out the available conditional parameters first\n",
    "#*************************************\n",
    "pm = paramManager.paramManager(datadir, paramdir)\n",
    "datafiles = pm.filenames(datadir)\n",
    "params = pm.getParams(datafiles[0]) \n",
    "print(params.keys())\n",
    "\n",
    "#note midiPitch has to be scaled since the large raw values interfere with the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset & dataloader\n",
    "#*************************************\n",
    "adataset = dataloader.AudioDataset(sr,seqLen,stride,\n",
    "                                  datadir=datadir,extension=\"wav\",\n",
    "                                  paramdir=paramdir,prop=['instID'],  #,'midiPitch'\n",
    "                                  transform=transform.Compose([mulawnEncode(256,0,1),array2tensor(torch.FloatTensor)]),\n",
    "                                  param_transform=dic2tensor(torch.FloatTensor),\n",
    "                                  target_transform=transform.Compose([mulaw(256),array2tensor(torch.LongTensor)]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=adataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for testing\n",
    "\n",
    "for i in range(len(adataset)):\n",
    "    sample,target = adataset[i]\n",
    "    #plt.plot(sample['audio'])\n",
    "    #for param in sample:\n",
    "    #    print(param)\n",
    "    print(sample)\n",
    "    print(target)\n",
    "    if i == 1:\n",
    "        break #just to visualize, note: audio is already mu-lawed\n",
    "        \n",
    "print(len(adataset))\n",
    "print(adataset.totalSamples)\n",
    "#input dim: (batch, seq, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model\n",
    "#*************************************\n",
    "class RNN(nn.Module):\n",
    "    # input size - the number of \"classes\"\n",
    "    def __init__(self, input_size, cond_size, batch_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.cond_size = cond_size\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers #no. of stacked GRU layers\n",
    "\n",
    "        self.i2h = nn.Linear(input_size+cond_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "\n",
    "    # input and cv are each one sequence element \n",
    "    def forward(self, input, hidden):\n",
    "        #print(\"input size is \" + str((input.size())))\n",
    "        \n",
    "        h1 = self.i2h(input)\n",
    "        #print(\"size of h1 is \" + str(h1.size()))\n",
    "        \n",
    "        h_out, hidden = self.gru(h1.view(self.batch_size,1,-1), hidden)\n",
    "        #print(\"h_out\"+str(h_out.size()))\n",
    "        \n",
    "        output = self.decoder(h_out.view(self.batch_size, -1))\n",
    "        #print(\"output2\"+str(output.size()))\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    # initialize hiddens for each minibatch\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, self.batch_size, self.hidden_size).type(torch.cuda.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training cycle\n",
    "#*************************************\n",
    "def train(epoch):\n",
    "    rnn.train() #put in training mode\n",
    "    ave_loss_over_steps = 0\n",
    "    \n",
    "    for step, (inp,target) in enumerate(train_loader):\n",
    "        #print('INP',inp.shape)\n",
    "        #print(\"TAR\",target.shape)\n",
    "        inp, target = inp.cuda(), target.cuda()\n",
    "        inp, target = Variable(inp), Variable(target)\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        hidden = rnn.init_hidden()\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        \n",
    "        for i in range(seqLen):\n",
    "            outputs, hidden = rnn(inp[:,i,:],hidden)\n",
    "            #print('target size',torch.squeeze(target[:,i],1).size())\n",
    "            loss += criterion(outputs, torch.squeeze(target[:,i],1))\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ave_loss_per_sample = loss.data[0]/seqLen   #over each minibatch\n",
    "        ave_loss_over_steps += ave_loss_per_sample\n",
    "        #print(count,ave_loss)\n",
    "        \n",
    "        if (step+1) % log_interval == 0:\n",
    "            print ('{:%Y-%m-%d %H:%M:%S} Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}'.format( \n",
    "                datetime.now(), epoch+1, num_epochs, step+1, len(adataset)//batch_size, ave_loss_over_steps/log_interval))\n",
    "            \n",
    "            list_of_losses.append(ave_loss_over_steps/log_interval)\n",
    "            ave_loss_over_steps = 0\n",
    "        \n",
    "        if step==max_steps:\n",
    "            break\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the network, optimizer and objective func\n",
    "#*************************************\n",
    "rnn = RNN(1,1,batch_size,40,256,4).cuda()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-08 13:02:38 Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huz\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-08 13:02:54 Epoch [1/1], Step [20/15200] Loss: 5.2819\n",
      "2018-08-08 13:03:07 Epoch [1/1], Step [40/15200] Loss: 5.1271\n",
      "2018-08-08 13:03:20 Epoch [1/1], Step [60/15200] Loss: 5.1105\n",
      "2018-08-08 13:03:33 Epoch [1/1], Step [80/15200] Loss: 4.9367\n",
      "2018-08-08 13:03:46 Epoch [1/1], Step [100/15200] Loss: 4.5660\n",
      "2018-08-08 13:03:59 Epoch [1/1], Step [120/15200] Loss: 4.2978\n",
      "2018-08-08 13:04:12 Epoch [1/1], Step [140/15200] Loss: 4.0687\n",
      "2018-08-08 13:04:25 Epoch [1/1], Step [160/15200] Loss: 3.9183\n",
      "2018-08-08 13:04:38 Epoch [1/1], Step [180/15200] Loss: 3.8056\n",
      "2018-08-08 13:04:51 Epoch [1/1], Step [200/15200] Loss: 3.7193\n",
      "2018-08-08 13:05:05 Epoch [1/1], Step [220/15200] Loss: 3.6112\n",
      "2018-08-08 13:05:18 Epoch [1/1], Step [240/15200] Loss: 3.5877\n",
      "2018-08-08 13:05:31 Epoch [1/1], Step [260/15200] Loss: 3.6506\n",
      "2018-08-08 13:05:44 Epoch [1/1], Step [280/15200] Loss: 3.5875\n",
      "2018-08-08 13:05:57 Epoch [1/1], Step [300/15200] Loss: 3.5153\n",
      "2018-08-08 13:06:10 Epoch [1/1], Step [320/15200] Loss: 3.4599\n",
      "2018-08-08 13:06:23 Epoch [1/1], Step [340/15200] Loss: 3.4254\n",
      "2018-08-08 13:06:36 Epoch [1/1], Step [360/15200] Loss: 3.3983\n",
      "2018-08-08 13:06:49 Epoch [1/1], Step [380/15200] Loss: 3.3883\n",
      "2018-08-08 13:07:02 Epoch [1/1], Step [400/15200] Loss: 3.3971\n",
      "2018-08-08 13:07:15 Epoch [1/1], Step [420/15200] Loss: 3.3720\n",
      "2018-08-08 13:07:28 Epoch [1/1], Step [440/15200] Loss: 3.3345\n",
      "2018-08-08 13:07:41 Epoch [1/1], Step [460/15200] Loss: 3.3029\n",
      "2018-08-08 13:07:54 Epoch [1/1], Step [480/15200] Loss: 3.3473\n",
      "2018-08-08 13:08:07 Epoch [1/1], Step [500/15200] Loss: 3.3862\n",
      "2018-08-08 13:08:20 Epoch [1/1], Step [520/15200] Loss: 3.3066\n",
      "2018-08-08 13:08:33 Epoch [1/1], Step [540/15200] Loss: 3.2528\n",
      "2018-08-08 13:08:46 Epoch [1/1], Step [560/15200] Loss: 3.2222\n",
      "2018-08-08 13:08:59 Epoch [1/1], Step [580/15200] Loss: 3.2820\n",
      "2018-08-08 13:09:12 Epoch [1/1], Step [600/15200] Loss: 3.2216\n",
      "2018-08-08 13:09:25 Epoch [1/1], Step [620/15200] Loss: 3.1766\n",
      "2018-08-08 13:09:38 Epoch [1/1], Step [640/15200] Loss: 3.2440\n",
      "2018-08-08 13:09:51 Epoch [1/1], Step [660/15200] Loss: 3.2281\n",
      "2018-08-08 13:10:04 Epoch [1/1], Step [680/15200] Loss: 3.2079\n",
      "2018-08-08 13:10:17 Epoch [1/1], Step [700/15200] Loss: 3.2371\n",
      "2018-08-08 13:10:31 Epoch [1/1], Step [720/15200] Loss: 3.1945\n",
      "2018-08-08 13:10:44 Epoch [1/1], Step [740/15200] Loss: 3.1553\n",
      "2018-08-08 13:10:57 Epoch [1/1], Step [760/15200] Loss: 3.2073\n",
      "2018-08-08 13:11:10 Epoch [1/1], Step [780/15200] Loss: 3.0902\n",
      "2018-08-08 13:11:23 Epoch [1/1], Step [800/15200] Loss: 3.1046\n",
      "2018-08-08 13:11:36 Epoch [1/1], Step [820/15200] Loss: 3.1533\n",
      "2018-08-08 13:11:49 Epoch [1/1], Step [840/15200] Loss: 3.1840\n",
      "2018-08-08 13:12:02 Epoch [1/1], Step [860/15200] Loss: 3.1192\n",
      "2018-08-08 13:12:15 Epoch [1/1], Step [880/15200] Loss: 3.1155\n",
      "2018-08-08 13:12:28 Epoch [1/1], Step [900/15200] Loss: 3.1049\n",
      "2018-08-08 13:12:41 Epoch [1/1], Step [920/15200] Loss: 3.1244\n",
      "2018-08-08 13:12:54 Epoch [1/1], Step [940/15200] Loss: 3.1085\n",
      "2018-08-08 13:13:07 Epoch [1/1], Step [960/15200] Loss: 3.0973\n",
      "2018-08-08 13:13:20 Epoch [1/1], Step [980/15200] Loss: 3.0685\n",
      "2018-08-08 13:13:33 Epoch [1/1], Step [1000/15200] Loss: 3.1090\n",
      "Training time taken: 0:10:55\n"
     ]
    }
   ],
   "source": [
    "# Train!\n",
    "#*************************************\n",
    "list_of_losses = []\n",
    "\n",
    "print('{:%Y-%m-%d %H:%M:%S} Starting training...'.format(datetime.now()))\n",
    "start_time = time.monotonic()\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)\n",
    "elapsed_time = time.monotonic() - start_time\n",
    "print('Training time taken:',time_taken(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ca89500fd0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over time\n",
    "#*************************************\n",
    "plt.figure()\n",
    "plt.plot(list_of_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
